[mlp]
lr = 0.001
epochs = 100
batch_size = 128
train_log = true

# model
dropout = 0.2
hidden_dims = [256, 128, 64, 32]


[conv2d_3x3_3]
lr = 0.001
epochs = 50
batch_size = 128
train_log = true

# model
dropout = 0.2


[conv2d_3x3_1]
lr = 0.001
epochs = 50
batch_size = 128
train_log = true

# model
dropout = 0.2


[conv1d_3_3]
lr = 0.001
epochs = 50
batch_size = 128
train_log = true

# model
dropout = 0.2


[conv1d_3_1]
lr = 0.001
epochs = 50
batch_size = 128
train_log = true

# model
dropout = 0.2


[lstm]
lr = 0.01
epochs = 100 
batch_size = 256
train_log = true

# model
hidden_dim = 32
num_layers =  3
dropout = 0


[gru]
lr = 0.001
epochs = 100
batch_size = 128
train_log = true

# model
hidden_dim = 64
num_layers = 3
dropout = 0.2


[bilstm]
lr = 0.001
epochs = 200
batch_size = 128
train_log = true

# model
hidden_dim = 64
num_layers = 3
dropout = 0.2


[bigru]
lr = 0.001
epochs = 100
batch_size = 128
train_log = true

# model
hidden_dim = 64
num_layers = 3
dropout = 0.2
